{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Should include entire pipeline, from data preprocessing to making final predictions.\n",
    "2. It should take in raw data as input.\n",
    "3. It should return predictions for your input. Here the input can be a single point or a set of points. <br>\n",
    "def final_fun_1(X):<br>\n",
    ".....<br>\n",
    ".....<br>\n",
    "..... # you will use the best model that you found out with your experiments<br>\n",
    "return predictions made on X ( Raw Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the raw test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw train data\n",
    "Test_Provider = pd.read_csv(\"Validation_Provider.csv\")\n",
    "Test_Beneficiary = pd.read_csv(\"Validation_Beneficiary.csv\")\n",
    "Test_Inpatient = pd.read_csv(\"Validation_Inpatient.csv\")\n",
    "Test_Outpatient = pd.read_csv(\"Validation_Outpatient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51008</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51011</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51012</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51016</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider PotentialFraud\n",
       "0  PRV51005            Yes\n",
       "1  PRV51008             No\n",
       "2  PRV51011             No\n",
       "3  PRV51012             No\n",
       "4  PRV51016             No"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Provider.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc , f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_feature_using_groupby(Test_df, groupby_col, operation_col, operation):\n",
    "    '''\n",
    "    This function groups the 'Test_df' DataFrame by 'groupby_col' and performs 'operation' on 'operation_col'.\n",
    "    It creates new columns for each specified operation and column.\n",
    "    '''\n",
    "\n",
    "    feature_dfs = []\n",
    "\n",
    "    for col in operation_col:\n",
    "        # create new column name for the dataframe\n",
    "        new_col_name = f'Per{\"_\".join(groupby_col)}_{operation}_{col}'\n",
    "        # perform the specified operation and create a new DataFrame\n",
    "        feature_df = Test_df.groupby(groupby_col)[col].transform(operation)\n",
    "        feature_df.rename(new_col_name, inplace=True)\n",
    "        feature_dfs.append(feature_df)\n",
    "\n",
    "    # Concatenate all feature DataFrames\n",
    "    result_df = pd.concat([Test_df] + feature_dfs, axis=1)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to preprocess raw test data\n",
    "def preprocess_test_data(Test_Provider, Test_Beneficiary, Test_Inpatient, Test_Outpatient):\n",
    "    \n",
    "    # Replacing 2 with 0 for chronic conditions, Zero indicates chronic condition is No\n",
    "    Test_Beneficiary = Test_Beneficiary.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,\n",
    "                               'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2, \n",
    "                               'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2, \n",
    "                               'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2 }, 0)\n",
    "\n",
    "    # For RenalDiseaseIndicator replacing 'Y' with 1\n",
    "    Test_Beneficiary = Test_Beneficiary.replace({'RenalDiseaseIndicator': 'Y'}, 1)\n",
    "\n",
    "    # convert all these columns datatypes to numeric\n",
    "    Test_Beneficiary[[\"ChronicCond_Alzheimer\", \"ChronicCond_Heartfailure\", \"ChronicCond_KidneyDisease\", \"ChronicCond_Cancer\", \"ChronicCond_ObstrPulmonary\", \"ChronicCond_Depression\", \"ChronicCond_Diabetes\", \"ChronicCond_IschemicHeart\", \"ChronicCond_Osteoporasis\", \"ChronicCond_rheumatoidarthritis\", \"ChronicCond_stroke\", \"RenalDiseaseIndicator\"]] = Test_Beneficiary[[\"ChronicCond_Alzheimer\", \"ChronicCond_Heartfailure\", \"ChronicCond_KidneyDisease\", \"ChronicCond_Cancer\", \"ChronicCond_ObstrPulmonary\", \"ChronicCond_Depression\", \"ChronicCond_Diabetes\", \"ChronicCond_IschemicHeart\", \"ChronicCond_Osteoporasis\", \"ChronicCond_rheumatoidarthritis\", \"ChronicCond_stroke\", \"RenalDiseaseIndicator\"]].apply(pd.to_numeric)\n",
    "\n",
    "    # calculate patient risk score by summing up all risk scores\n",
    "    Test_Beneficiary['Patient_Risk_Score'] = Test_Beneficiary['ChronicCond_Alzheimer'] + Test_Beneficiary['ChronicCond_Heartfailure'] + \\\n",
    "                                            Test_Beneficiary['ChronicCond_KidneyDisease'] + Test_Beneficiary['ChronicCond_Cancer'] +\\\n",
    "                                            Test_Beneficiary['ChronicCond_ObstrPulmonary'] + Test_Beneficiary['ChronicCond_Depression'] +\\\n",
    "                                        Test_Beneficiary['ChronicCond_Diabetes'] + Test_Beneficiary['ChronicCond_IschemicHeart'] +\\\n",
    "                                        Test_Beneficiary['ChronicCond_Osteoporasis'] + Test_Beneficiary['ChronicCond_rheumatoidarthritis'] +\\\n",
    "                                        Test_Beneficiary['ChronicCond_stroke'] + Test_Beneficiary['RenalDiseaseIndicator'] \n",
    "\n",
    "    # Replacing '2' with '0' for Gender Type\n",
    "    Test_Beneficiary = Test_Beneficiary.replace({'Gender': 2}, 0)\n",
    "\n",
    "    # Convert Date of Birth and Date of Death from String to Datetime format\n",
    "    Test_Beneficiary['DOB'] = pd.to_datetime(Test_Beneficiary['DOB'] , format = '%Y-%m-%d')\n",
    "    Test_Beneficiary['DOD'] = pd.to_datetime(Test_Beneficiary['DOD'],format = '%Y-%m-%d')\n",
    "\n",
    "    # Get the birth month and Birth year for DOB and DOD\n",
    "    Test_Beneficiary['Birth_Year'] = Test_Beneficiary['DOB'].dt.year\n",
    "    Test_Beneficiary['Birth_Month'] = Test_Beneficiary['DOB'].dt.month\n",
    "\n",
    "    Test_Beneficiary['Patient_Age'] = round(((Test_Beneficiary['DOD'] - Test_Beneficiary['DOB']).dt.days)/365)\n",
    "    Test_Beneficiary.Patient_Age.fillna(round(((pd.to_datetime('2009-12-01',format ='%Y-%m-%d')-Test_Beneficiary['DOB']).dt.days)/365),inplace=True)\n",
    "\n",
    "    # Set value=1 if the patient is dead i.e DOD value is not null\n",
    "    Test_Beneficiary['isDead'] = 0\n",
    "    Test_Beneficiary.loc[Test_Beneficiary.DOD.notna(), 'isDead'] = 1\n",
    "\n",
    "    # convert ClaimStartDt, ClaimEndDt from string to datetime format\n",
    "    Test_Inpatient['ClaimStartDt'] = pd.to_datetime(Test_Inpatient['ClaimStartDt'] , format = '%Y-%m-%d')\n",
    "    Test_Inpatient['ClaimEndDt'] = pd.to_datetime(Test_Inpatient['ClaimEndDt'],format = '%Y-%m-%d')\n",
    "\n",
    "    # convert AdmissionDt, DischargeDt from string to datetime format\n",
    "    Test_Inpatient['AdmissionDt'] = pd.to_datetime(Test_Inpatient['AdmissionDt'] , format = '%Y-%m-%d')\n",
    "    Test_Inpatient['DischargeDt'] = pd.to_datetime(Test_Inpatient['DischargeDt'],format = '%Y-%m-%d')\n",
    "\n",
    "    # Calculate Hospitalization_Duration = DischargeDt - AdmissionDt\n",
    "    Test_Inpatient['Hospitalization_Duration'] = ((Test_Inpatient['DischargeDt'] - Test_Inpatient['AdmissionDt']).dt.days)+1\n",
    "    # Calculate Claim_Period = ClaimEndDt - ClaimStartDt\n",
    "    Test_Inpatient['Claim_Period'] = ((Test_Inpatient['ClaimEndDt'] - Test_Inpatient['ClaimStartDt']).dt.days)+1\n",
    "\n",
    "    # ExtraClaimDays = Claim_Period - Hospitalization_Duration\n",
    "    Test_Inpatient['ExtraClaimDays'] = np.where(Test_Inpatient['Claim_Period']>Test_Inpatient['Hospitalization_Duration'], Test_Inpatient['Claim_Period'] - Test_Inpatient['Hospitalization_Duration'], 0)\n",
    "\n",
    "    # Get the months and year of claim start and claim end\n",
    "    Test_Inpatient['ClaimStart_Year'] = Test_Inpatient['ClaimStartDt'].dt.year\n",
    "    Test_Inpatient['ClaimStart_Month'] = Test_Inpatient['ClaimStartDt'].dt.month\n",
    "    Test_Inpatient['ClaimEnd_Year'] = Test_Inpatient['ClaimEndDt'].dt.year\n",
    "    Test_Inpatient['ClaimEnd_Month'] = Test_Inpatient['ClaimEndDt'].dt.month\n",
    "\n",
    "    # Get the month and year of Admission_Year and Admission_Month\n",
    "    Test_Inpatient['Admission_Year'] = Test_Inpatient['AdmissionDt'].dt.year\n",
    "    Test_Inpatient['Admission_Month'] = Test_Inpatient['AdmissionDt'].dt.month\n",
    "\n",
    "    Test_Inpatient['Discharge_Year'] = Test_Inpatient['DischargeDt'].dt.year\n",
    "    Test_Inpatient['Discharge_Month'] = Test_Inpatient['DischargeDt'].dt.month\n",
    "\n",
    "    # convert ClaimStartDt, ClaimEndDt from string to datetime format\n",
    "    Test_Outpatient['ClaimStartDt'] = pd.to_datetime(Test_Outpatient['ClaimStartDt'] , format = '%Y-%m-%d')\n",
    "    Test_Outpatient['ClaimEndDt'] = pd.to_datetime(Test_Outpatient['ClaimEndDt'],format = '%Y-%m-%d')\n",
    "\n",
    "    # Get the months and year of claim start and claim end\n",
    "    Test_Outpatient['ClaimStart_Year'] = Test_Outpatient['ClaimStartDt'].dt.year\n",
    "    Test_Outpatient['ClaimStart_Month'] = Test_Outpatient['ClaimStartDt'].dt.month\n",
    "    Test_Outpatient['ClaimEnd_Year'] = Test_Outpatient['ClaimEndDt'].dt.year\n",
    "    Test_Outpatient['ClaimEnd_Month'] = Test_Outpatient['ClaimEndDt'].dt.month\n",
    "\n",
    "    # Calculate Claim_Period = ClaimEndDt - ClaimStartDt\n",
    "    Test_Outpatient['Claim_Period'] = ((Test_Outpatient['ClaimEndDt'] - Test_Outpatient['ClaimStartDt']).dt.days)+1\n",
    "\n",
    "    # Create a new column Inpatient_or_Outpatient where Inpatient =1 and Outpatient = 0\n",
    "    Test_Inpatient['Inpatient_or_Outpatient'] = 1\n",
    "    Test_Outpatient['Inpatient_or_Outpatient'] = 0\n",
    "\n",
    "    # Merge inpatient and outpatient dataframes based on common columns\n",
    "    common_columns_test = [ idx for idx in Test_Outpatient.columns if idx in Test_Inpatient.columns]\n",
    "    Inpatient_Outpatient_Merge_Te = pd.merge(Test_Inpatient, Test_Outpatient, left_on = common_columns_test, right_on = common_columns_test,how = 'outer')\n",
    "\n",
    "    # Merge beneficiary details with inpatient and outpatient data\n",
    "    Inpatient_Outpatient_Beneficiary_Merge_Te = pd.merge(Inpatient_Outpatient_Merge_Te, Test_Beneficiary,\n",
    "                                                      left_on='BeneID',right_on='BeneID',how='inner')\n",
    "\n",
    "    Final_Dataset_Test = pd.merge(Inpatient_Outpatient_Beneficiary_Merge_Te, Test_Provider , how = 'inner', on = 'Provider' )\n",
    "\n",
    "    # create new feature total reimbursement amount for inpatient and outpatient\n",
    "    Final_Dataset_Test['IP_OP_TotalReimbursementAmt'] = Final_Dataset_Test['IPAnnualReimbursementAmt'] + Final_Dataset_Test['OPAnnualReimbursementAmt']\n",
    "    # create new feature total deductible amount for inpatient and outpatient\n",
    "    Final_Dataset_Test['IP_OP_AnnualDeductibleAmt'] = Final_Dataset_Test['IPAnnualDeductibleAmt'] + Final_Dataset_Test['OPAnnualDeductibleAmt']\n",
    "\n",
    "    # Fill missing results using 0\n",
    "    Final_Dataset_Test = Final_Dataset_Test.fillna(0).copy()\n",
    "    \n",
    "    # group by columns to create feature\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'NoOfMonths_PartACov', 'NoOfMonths_PartBCov', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['Provider'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['BeneID'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['AttendingPhysician'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['OperatingPhysician'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['OtherPhysician'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['DiagnosisGroupCode'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmAdmitDiagnosisCode'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_1'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_2'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_3'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_4'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_5'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmProcedureCode_6'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_1'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_2'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_3'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_4'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_5'], columns, 'mean')\n",
    "\n",
    "    columns = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Patient_Age', 'Hospitalization_Duration', 'Claim_Period', 'Patient_Risk_Score']\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['ClmDiagnosisCode_6'], columns, 'mean')\n",
    "\n",
    "    # Count the claims per provider\n",
    "    Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, ['Provider'], ['ClaimID'], 'count')\n",
    "\n",
    "    columns = ['ClaimID']\n",
    "    grp_by_cols = ['BeneID', 'AttendingPhysician', 'OtherPhysician', 'OperatingPhysician', 'ClmAdmitDiagnosisCode', 'ClmProcedureCode_1',\n",
    "                   'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',\n",
    "                   'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6', 'DiagnosisGroupCode']\n",
    "    for ele in grp_by_cols:\n",
    "        lst = ['Provider', ele]\n",
    "        Final_Dataset_Test =  create_feature_using_groupby(Final_Dataset_Test, lst, columns, 'count')\n",
    "\n",
    "    # remove the columns which are not required\n",
    "    remove_columns=['BeneID', 'ClaimID', 'ClaimStartDt','ClaimEndDt','AttendingPhysician','OperatingPhysician', 'OtherPhysician',\n",
    "                    'ClmDiagnosisCode_1','ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4','ClmDiagnosisCode_5',\n",
    "                    'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7','ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10',\n",
    "                    'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3','ClmProcedureCode_4', 'ClmProcedureCode_5',\n",
    "                    'ClmProcedureCode_6','ClmAdmitDiagnosisCode', 'AdmissionDt','ClaimStart_Year', 'ClaimStart_Year', 'ClaimStart_Month',\n",
    "                    'ClaimEnd_Year', 'ClaimEnd_Month', 'Admission_Year', 'Admission_Month', 'Discharge_Year', 'Discharge_Month',\n",
    "                    'DischargeDt', 'DiagnosisGroupCode','DOB', 'DOD','Birth_Year', 'Birth_Month','State', 'County']\n",
    "\n",
    "    Final_Dataset_Test_FE=Final_Dataset_Test.drop(columns=remove_columns, axis=1)\n",
    "\n",
    "    # Convert type of Gender and Race to categorical\n",
    "    Final_Dataset_Test_FE.Gender=Final_Dataset_Test_FE.Gender.astype('category')\n",
    "    Final_Dataset_Test_FE.Race=Final_Dataset_Test_FE.Race.astype('category')\n",
    "\n",
    "    # Do one hot encoding for gender and Race\n",
    "    Final_Dataset_Test_FE=pd.get_dummies(Final_Dataset_Test_FE,columns=['Gender','Race'])\n",
    "\n",
    "    if \"PotentialFraud\" in list(Test_Provider.columns):\n",
    "        Final_Dataset_Provider_Test = Final_Dataset_Test_FE.groupby(['Provider','PotentialFraud'],as_index=False).agg('sum')\n",
    "        Final_Dataset_Provider_Test.PotentialFraud.replace(['Yes','No'],['1','0'],inplace=True)\n",
    "        Final_Dataset_Provider_Test.PotentialFraud=Final_Dataset_Provider_Test.PotentialFraud.astype('int64')\n",
    "        return Final_Dataset_Provider_Test\n",
    "    else:\n",
    "        Final_Dataset_Provider_Test  = Final_Dataset_Test_FE.groupby(['Provider'],as_index=False).agg('sum')\n",
    "        return Final_Dataset_Provider_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prob(clf, data): \n",
    "    # predicts the probabability of class label using the model\n",
    "    y_pred = clf.predict_proba(data)[:,1]\n",
    "    return y_pred\n",
    "\n",
    "def predict_with_best_t(proba, threshold):\n",
    "    predictions = []\n",
    "    for i in proba:\n",
    "        if i>=threshold:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw train data\n",
    "Test_Provider = pd.read_csv(\"Validation_Provider.csv\")\n",
    "Test_Beneficiary = pd.read_csv(\"Validation_Beneficiary.csv\")\n",
    "Test_Inpatient = pd.read_csv(\"Validation_Inpatient.csv\")\n",
    "Test_Outpatient = pd.read_csv(\"Validation_Outpatient.csv\")\n",
    "# drop PotentialFraud column for final_fun_1\n",
    "Test_Provider_1 = Test_Provider.drop(\"PotentialFraud\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary which will contain all the files\n",
    "X = {\"Test_Provider\":Test_Provider_1, \"Test_Beneficiary\":Test_Beneficiary, \"Test_Inpatient\":Test_Inpatient, \"Test_Outpatient\":Test_Outpatient}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    # Load the raw train data\n",
    "    Test_Provider = X['Test_Provider']\n",
    "    Test_Beneficiary = X['Test_Beneficiary']\n",
    "    Test_Inpatient = X['Test_Inpatient']\n",
    "    Test_Outpatient = X['Test_Outpatient']\n",
    "    \n",
    "    # preprocess tha data\n",
    "    Final_Dataset_Provider_Test = preprocess_test_data(Test_Provider, Test_Beneficiary, Test_Inpatient, Test_Outpatient)\n",
    "    \n",
    "    # drop provider column\n",
    "    x_test_provider = Final_Dataset_Provider_Test[['Provider']]\n",
    "    x_test = Final_Dataset_Provider_Test.drop(axis=1,columns=['Provider'])\n",
    "\n",
    "    # Standardize the data\n",
    "    standard_scaler = StandardScaler()\n",
    "    standard_scaler.fit(x_test)\n",
    "    x_test = standard_scaler.transform(x_test)\n",
    "    \n",
    "    # load the stored model and parameters\n",
    "    sampled_col_indices_list = joblib.load('sampled_col_indices_list.pkl')\n",
    "    base_model_list = joblib.load('base_model_list.pkl')\n",
    "    random_forest = joblib.load('random_forest.pkl')\n",
    "    best_t = joblib.load('best_t.pkl')\n",
    "\n",
    "    # pass x_test through base learners to generate data for meta model\n",
    "    pred_data_list = []\n",
    "    for i in range(len(base_model_list)):\n",
    "        x_test_base_learner = x_test[:, sampled_col_indices_list[i]]\n",
    "        pred_data = base_model_list[i].predict_proba(x_test_base_learner)[:,1]\n",
    "        pred_data_list.append(pred_data)\n",
    "    x_test_meta_model = np.vstack(pred_data_list).transpose()\n",
    "    y_test_pred = pred_prob(random_forest, x_test_meta_model)\n",
    "    y_test_prediction = predict_with_best_t(y_test_pred, best_t)\n",
    "    \n",
    "    # add prediction in predicted_label column\n",
    "    x_test_provider['predicted_label'] = y_test_prediction\n",
    "    \n",
    "    return x_test_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gurram koushik reddy\\AppData\\Local\\Temp\\ipykernel_29516\\2055381992.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Final_Dataset_Provider_Test  = Final_Dataset_Test_FE.groupby(['Provider'],as_index=False).agg('sum')\n",
      "C:\\Users\\Gurram koushik reddy\\AppData\\Local\\Temp\\ipykernel_29516\\2371723151.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test_provider['predicted_label'] = y_test_prediction\n"
     ]
    }
   ],
   "source": [
    "# call final_fun_1 for preprocessing, prediction\n",
    "x_test_provider = final_fun_1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRV51017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRV51029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRV51041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRV51054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRV51059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  predicted_label\n",
       "0  PRV51005                1\n",
       "1  PRV51008                0\n",
       "2  PRV51011                0\n",
       "3  PRV51012                0\n",
       "4  PRV51016                0\n",
       "5  PRV51017                0\n",
       "6  PRV51029                0\n",
       "7  PRV51041                0\n",
       "8  PRV51054                0\n",
       "9  PRV51059                1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted labels\n",
    "x_test_provider.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function-2\n",
    "1. Should include entire pipeline, from data preprocessing to making final predictions.\n",
    "2. It should take in raw data as input along with its target values.\n",
    "3. It should return the metric value that you are judging your models on. <br>\n",
    "def final_fun_2(X,Y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw train data\n",
    "Test_Provider = pd.read_csv(\"Validation_Provider.csv\")\n",
    "Test_Beneficiary = pd.read_csv(\"Validation_Beneficiary.csv\")\n",
    "Test_Inpatient = pd.read_csv(\"Validation_Inpatient.csv\")\n",
    "Test_Outpatient = pd.read_csv(\"Validation_Outpatient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary which will contain all the files\n",
    "X = {\"Test_Provider\":Test_Provider, \"Test_Beneficiary\":Test_Beneficiary, \"Test_Inpatient\":Test_Inpatient, \"Test_Outpatient\":Test_Outpatient}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_test_roc(test_fpr, test_tpr):\n",
    "    # calculate auc for test\n",
    "    plt.figure(figsize=(10,6))\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "    plt.plot(test_fpr, test_tpr, label=\"Test AUC =\"+\"{:.4f}\".format(test_auc))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"False Positive Rate(FPR)\", size = 14)\n",
    "    plt.ylabel(\"True Positive Rate(TPR)\", size = 14)\n",
    "    plt.title(\"Area Under Curve\", size = 16)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def draw_test_confusion_matrix(best_t, x_test, y_test, y_test_pred):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    test_prediction = predict_with_best_t(y_test_pred, best_t)\n",
    "    cm = confusion_matrix(y_test, test_prediction)\n",
    "    sns.heatmap(cm, annot=True, fmt='d') #, ax=ax[1]\n",
    "    plt.title('Test Dataset Confusion Matrix', size = 16)\n",
    "    plt.xlabel(\"Predicted Label\", size = 14)\n",
    "    plt.ylabel(\"Actual Label\", size = 14)\n",
    "    plt.show()\n",
    "    return test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_test_model(clf, x_test, y_test, best_t):\n",
    "    # predict the probability of test data\n",
    "    y_test_pred = pred_prob(clf, x_test)\n",
    "    # calculate tpr, fpr for diffeent thresholds using roc_curve\n",
    "    test_fpr, test_tpr, te_thresholds = roc_curve(y_test, y_test_pred)\n",
    "    \n",
    "    # calculate auc for train and test\n",
    "    test_auc = auc(test_fpr, test_tpr)\n",
    "    print(\"Test AUC = \", test_auc)\n",
    "    \n",
    "    draw_test_roc(test_fpr, test_tpr)\n",
    "    #def draw_test_confusion_matrix(best_t, x_test, y_test, y_test_pred):\n",
    "    test_prediction = draw_test_confusion_matrix(best_t, x_test, y_test, y_test_pred)\n",
    "    test_f1_score = f1_score(y_test, test_prediction)\n",
    "    return test_auc, test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X):\n",
    "    # Load the raw train data\n",
    "    Test_Provider = X['Test_Provider']\n",
    "    Test_Beneficiary = X['Test_Beneficiary']\n",
    "    Test_Inpatient = X['Test_Inpatient']\n",
    "    Test_Outpatient = X['Test_Outpatient']\n",
    "    \n",
    "    # preprocess tha data\n",
    "    Final_Dataset_Provider_Test = preprocess_test_data(Test_Provider, Test_Beneficiary, Test_Inpatient, Test_Outpatient)\n",
    "    \n",
    "    # Seperate dependent and independent variables\n",
    "    x_test_provider = Final_Dataset_Provider_Test[['Provider','PotentialFraud']]\n",
    "    x_test = Final_Dataset_Provider_Test.drop(columns=['Provider','PotentialFraud'],axis=1)\n",
    "    y_test = Final_Dataset_Provider_Test['PotentialFraud']\n",
    "\n",
    "    # Standardize the data\n",
    "    standard_scaler = StandardScaler()\n",
    "    standard_scaler.fit(x_test)\n",
    "    x_test = standard_scaler.transform(x_test)\n",
    "    \n",
    "    # load the stored model and parameters\n",
    "    sampled_col_indices_list = joblib.load('sampled_col_indices_list.pkl')\n",
    "    base_model_list = joblib.load('base_model_list.pkl')\n",
    "    random_forest = joblib.load('random_forest.pkl')\n",
    "    best_t = joblib.load('best_t.pkl')\n",
    "\n",
    "    # pass x_test through base learners to generate data for meta model\n",
    "    pred_data_list = []\n",
    "    for i in range(len(base_model_list)):\n",
    "        x_test_base_learner = x_test[:, sampled_col_indices_list[i]]\n",
    "        pred_data = base_model_list[i].predict_proba(x_test_base_learner)[:,1]\n",
    "        pred_data_list.append(pred_data)\n",
    "    x_test_meta_model = np.vstack(pred_data_list).transpose()\n",
    "    y_test_pred = pred_prob(random_forest, x_test_meta_model)\n",
    "    y_test_prediction = predict_with_best_t(y_test_pred, best_t)\n",
    "    \n",
    "    # add prediction in predicted_label column\n",
    "    x_test_provider['predicted_label'] = y_test_prediction\n",
    "    \n",
    "    # Validate RF model\n",
    "    test_auc, test_f1_score = validate_test_model(random_forest, x_test_meta_model, y_test, best_t)\n",
    "    print(\"Best Threshold = {:.4f}\".format(best_t))\n",
    "    print(\"Model AUC is : {:.4f}\".format(test_auc))\n",
    "    print(\"Model F1 Score is : {:.4f}\".format(test_f1_score))\n",
    "   \n",
    "    return x_test_provider, test_auc, test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call final_fun_2 for prediction\n",
    "x_test_provider, test_auc, test_f1_score = final_fun_2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRV51017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRV51029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRV51041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRV51054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRV51059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  PotentialFraud  predicted_label\n",
       "0  PRV51005               1                1\n",
       "1  PRV51008               0                0\n",
       "2  PRV51011               0                0\n",
       "3  PRV51012               0                0\n",
       "4  PRV51016               0                0\n",
       "5  PRV51017               0                0\n",
       "6  PRV51029               0                0\n",
       "7  PRV51041               0                0\n",
       "8  PRV51054               0                0\n",
       "9  PRV51059               1                1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print actual label along with predicted label\n",
    "x_test_provider.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>PRV57712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>PRV57715</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>PRV57720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>PRV57732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>PRV57741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>PRV57747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>PRV57748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>PRV57756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>PRV57758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>PRV57759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Provider  PotentialFraud  predicted_label\n",
       "1072  PRV57712               0                0\n",
       "1073  PRV57715               0                1\n",
       "1074  PRV57720               0                0\n",
       "1075  PRV57732               0                0\n",
       "1076  PRV57741               0                0\n",
       "1077  PRV57747               0                0\n",
       "1078  PRV57748               0                0\n",
       "1079  PRV57756               0                0\n",
       "1080  PRV57758               0                0\n",
       "1081  PRV57759               0                0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_provider.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_provider.to_csv('x_test_provider.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
